{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3 in TensorflowLite.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selgan007/YOLO-Training/blob/master/YOLOv3_in_TensorflowLite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgyNAXvPM4nE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "338a50e2-d137-4c60-b048-aeac95511dac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rkC4QaRNAmT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4e8b6a2e-7341-4498-bb67-298c8b58fdcd"
      },
      "source": [
        "!git clone https://github.com/qqwweee/keras-yolo3.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-yolo3'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "Receiving objects:   0% (1/144)   \rReceiving objects:   1% (2/144)   \rReceiving objects:   2% (3/144)   \rReceiving objects:   3% (5/144)   \rReceiving objects:   4% (6/144)   \rReceiving objects:   5% (8/144)   \rReceiving objects:   6% (9/144)   \rReceiving objects:   7% (11/144)   \rReceiving objects:   8% (12/144)   \rReceiving objects:   9% (13/144)   \rReceiving objects:  10% (15/144)   \rReceiving objects:  11% (16/144)   \rReceiving objects:  12% (18/144)   \rReceiving objects:  13% (19/144)   \rReceiving objects:  14% (21/144)   \rReceiving objects:  15% (22/144)   \rReceiving objects:  16% (24/144)   \rReceiving objects:  17% (25/144)   \rReceiving objects:  18% (26/144)   \rReceiving objects:  19% (28/144)   \rReceiving objects:  20% (29/144)   \rReceiving objects:  21% (31/144)   \rReceiving objects:  22% (32/144)   \rReceiving objects:  23% (34/144)   \rReceiving objects:  24% (35/144)   \rReceiving objects:  25% (36/144)   \rremote: Total 144 (delta 0), reused 0 (delta 0), pack-reused 144\u001b[K\n",
            "Receiving objects:  26% (38/144)   \rReceiving objects:  27% (39/144)   \rReceiving objects:  28% (41/144)   \rReceiving objects:  29% (42/144)   \rReceiving objects:  30% (44/144)   \rReceiving objects:  31% (45/144)   \rReceiving objects:  32% (47/144)   \rReceiving objects:  33% (48/144)   \rReceiving objects:  34% (49/144)   \rReceiving objects:  35% (51/144)   \rReceiving objects:  36% (52/144)   \rReceiving objects:  37% (54/144)   \rReceiving objects:  38% (55/144)   \rReceiving objects:  39% (57/144)   \rReceiving objects:  40% (58/144)   \rReceiving objects:  41% (60/144)   \rReceiving objects:  42% (61/144)   \rReceiving objects:  43% (62/144)   \rReceiving objects:  44% (64/144)   \rReceiving objects:  45% (65/144)   \rReceiving objects:  46% (67/144)   \rReceiving objects:  47% (68/144)   \rReceiving objects:  48% (70/144)   \rReceiving objects:  49% (71/144)   \rReceiving objects:  50% (72/144)   \rReceiving objects:  51% (74/144)   \rReceiving objects:  52% (75/144)   \rReceiving objects:  53% (77/144)   \rReceiving objects:  54% (78/144)   \rReceiving objects:  55% (80/144)   \rReceiving objects:  56% (81/144)   \rReceiving objects:  57% (83/144)   \rReceiving objects:  58% (84/144)   \rReceiving objects:  59% (85/144)   \rReceiving objects:  60% (87/144)   \rReceiving objects:  61% (88/144)   \rReceiving objects:  62% (90/144)   \rReceiving objects:  63% (91/144)   \rReceiving objects:  64% (93/144)   \rReceiving objects:  65% (94/144)   \rReceiving objects:  66% (96/144)   \rReceiving objects:  67% (97/144)   \rReceiving objects:  68% (98/144)   \rReceiving objects:  69% (100/144)   \rReceiving objects:  70% (101/144)   \rReceiving objects:  71% (103/144)   \rReceiving objects:  72% (104/144)   \rReceiving objects:  73% (106/144)   \rReceiving objects:  74% (107/144)   \rReceiving objects:  75% (108/144)   \rReceiving objects:  76% (110/144)   \rReceiving objects:  77% (111/144)   \rReceiving objects:  78% (113/144)   \rReceiving objects:  79% (114/144)   \rReceiving objects:  80% (116/144)   \rReceiving objects:  81% (117/144)   \rReceiving objects:  82% (119/144)   \rReceiving objects:  83% (120/144)   \rReceiving objects:  84% (121/144)   \rReceiving objects:  85% (123/144)   \rReceiving objects:  86% (124/144)   \rReceiving objects:  87% (126/144)   \rReceiving objects:  88% (127/144)   \rReceiving objects:  89% (129/144)   \rReceiving objects:  90% (130/144)   \rReceiving objects:  91% (132/144)   \rReceiving objects:  92% (133/144)   \rReceiving objects:  93% (134/144)   \rReceiving objects:  94% (136/144)   \rReceiving objects:  95% (137/144)   \rReceiving objects:  96% (139/144)   \rReceiving objects:  97% (140/144)   \rReceiving objects:  98% (142/144)   \rReceiving objects:  99% (143/144)   \rReceiving objects: 100% (144/144)   \rReceiving objects: 100% (144/144), 150.95 KiB | 425.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/65)   \rResolving deltas:   3% (2/65)   \rResolving deltas:   4% (3/65)   \rResolving deltas:  12% (8/65)   \rResolving deltas:  15% (10/65)   \rResolving deltas:  16% (11/65)   \rResolving deltas:  32% (21/65)   \rResolving deltas:  40% (26/65)   \rResolving deltas:  43% (28/65)   \rResolving deltas:  44% (29/65)   \rResolving deltas:  46% (30/65)   \rResolving deltas:  64% (42/65)   \rResolving deltas:  66% (43/65)   \rResolving deltas:  67% (44/65)   \rResolving deltas:  78% (51/65)   \rResolving deltas:  80% (52/65)   \rResolving deltas:  86% (56/65)   \rResolving deltas:  89% (58/65)   \rResolving deltas:  93% (61/65)   \rResolving deltas:  98% (64/65)   \rResolving deltas: 100% (65/65)   \rResolving deltas: 100% (65/65), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2KGIxQaNrDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "763a98d0-5091-4d4d-d297-9e5b40c6ad5f"
      },
      "source": [
        "cd keras-yolo3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBgG8pTZNt3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bcb3e94d-4787-432b-b105-909bd9b1d0c6"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-17 01:40:58--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  23.0MB/s    in 11s     \n",
            "\n",
            "2019-09-17 01:41:09 (21.4 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khZisnDXN6MU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cfe6262-71e9-4393-e253-7b6ad324c705"
      },
      "source": [
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "Loading weights.\n",
            "Weights Header:  0 2 0 [32013312]\n",
            "Parsing Darknet config.\n",
            "Creating Keras model.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "Parsing section net_0\n",
            "Parsing section convolutional_0\n",
            "conv2d bn leaky (3, 3, 3, 32)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-09-17 01:41:16.733498: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-17 01:41:16.736052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c2d480 executing computations on platform Host. Devices:\n",
            "2019-09-17 01:41:16.736084: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-17 01:41:16.741342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-17 01:41:16.900676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:16.901564: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c2dd40 executing computations on platform CUDA. Devices:\n",
            "2019-09-17 01:41:16.901601: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-17 01:41:16.903090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:16.903806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-17 01:41:16.917458: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-17 01:41:17.125424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-17 01:41:17.222385: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-17 01:41:17.246992: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-17 01:41:17.480807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-17 01:41:17.668374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-17 01:41:18.092800: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-17 01:41:18.093179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:18.094033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:18.094734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-17 01:41:18.098137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-17 01:41:18.099751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-17 01:41:18.099799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-17 01:41:18.099818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-17 01:41:18.104434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:18.105250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:41:18.106004: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-17 01:41:18.106067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "Parsing section convolutional_1\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section convolutional_2\n",
            "conv2d bn leaky (1, 1, 64, 32)\n",
            "Parsing section convolutional_3\n",
            "conv2d bn leaky (3, 3, 32, 64)\n",
            "Parsing section shortcut_0\n",
            "Parsing section convolutional_4\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section convolutional_5\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_6\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_1\n",
            "Parsing section convolutional_7\n",
            "conv2d bn leaky (1, 1, 128, 64)\n",
            "Parsing section convolutional_8\n",
            "conv2d bn leaky (3, 3, 64, 128)\n",
            "Parsing section shortcut_2\n",
            "Parsing section convolutional_9\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_10\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_11\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_3\n",
            "Parsing section convolutional_12\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_13\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_4\n",
            "Parsing section convolutional_14\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_15\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_5\n",
            "Parsing section convolutional_16\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_17\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_6\n",
            "Parsing section convolutional_18\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_19\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_7\n",
            "Parsing section convolutional_20\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_21\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_8\n",
            "Parsing section convolutional_22\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_23\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_9\n",
            "Parsing section convolutional_24\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_25\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section shortcut_10\n",
            "Parsing section convolutional_26\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_27\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_28\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_11\n",
            "Parsing section convolutional_29\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_30\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_12\n",
            "Parsing section convolutional_31\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_32\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_13\n",
            "Parsing section convolutional_33\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_34\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_14\n",
            "Parsing section convolutional_35\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_36\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_15\n",
            "Parsing section convolutional_37\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_38\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_16\n",
            "Parsing section convolutional_39\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_40\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_17\n",
            "Parsing section convolutional_41\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_42\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section shortcut_18\n",
            "Parsing section convolutional_43\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_44\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_45\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_19\n",
            "Parsing section convolutional_46\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_47\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_20\n",
            "Parsing section convolutional_48\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_49\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_21\n",
            "Parsing section convolutional_50\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_51\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section shortcut_22\n",
            "Parsing section convolutional_52\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_53\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_54\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_55\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_56\n",
            "conv2d bn leaky (1, 1, 1024, 512)\n",
            "Parsing section convolutional_57\n",
            "conv2d bn leaky (3, 3, 512, 1024)\n",
            "Parsing section convolutional_58\n",
            "conv2d    linear (1, 1, 1024, 255)\n",
            "Parsing section yolo_0\n",
            "Parsing section route_0\n",
            "Parsing section convolutional_59\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section upsample_0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "Parsing section route_1\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_1/ResizeNearestNeighbor:0' shape=(?, ?, ?, 256) dtype=float32>, <tf.Tensor 'add_19/add:0' shape=(?, ?, ?, 512) dtype=float32>]\n",
            "Parsing section convolutional_60\n",
            "conv2d bn leaky (1, 1, 768, 256)\n",
            "Parsing section convolutional_61\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_62\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_63\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_64\n",
            "conv2d bn leaky (1, 1, 512, 256)\n",
            "Parsing section convolutional_65\n",
            "conv2d bn leaky (3, 3, 256, 512)\n",
            "Parsing section convolutional_66\n",
            "conv2d    linear (1, 1, 512, 255)\n",
            "Parsing section yolo_1\n",
            "Parsing section route_2\n",
            "Parsing section convolutional_67\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section upsample_1\n",
            "Parsing section route_3\n",
            "Concatenating route layers: [<tf.Tensor 'up_sampling2d_2/ResizeNearestNeighbor:0' shape=(?, ?, ?, 128) dtype=float32>, <tf.Tensor 'add_11/add:0' shape=(?, ?, ?, 256) dtype=float32>]\n",
            "Parsing section convolutional_68\n",
            "conv2d bn leaky (1, 1, 384, 128)\n",
            "Parsing section convolutional_69\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_70\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_71\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_72\n",
            "conv2d bn leaky (1, 1, 256, 128)\n",
            "Parsing section convolutional_73\n",
            "conv2d bn leaky (3, 3, 128, 256)\n",
            "Parsing section convolutional_74\n",
            "conv2d    linear (1, 1, 256, 255)\n",
            "Parsing section yolo_2\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 3 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 6 18432       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 3 2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 3 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 3 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 6 18432       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 6 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 6 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 8192        leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 1 512         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 1 0           leaky_re_lu_5[0][0]              \n",
            "                                                                 leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 8192        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 1 73728       leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 1 512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, None, None, 1 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 1 0           add_2[0][0]                      \n",
            "                                                                 leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 1 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 2 294912      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 2 1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 2 1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 2 0           leaky_re_lu_10[0][0]             \n",
            "                                                                 leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 1 32768       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 1 512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 2 1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 2 0           add_4[0][0]                      \n",
            "                                                                 leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 32768       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 2 1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 2 0           add_5[0][0]                      \n",
            "                                                                 leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 1 32768       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 1 512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 2 1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 2 0           add_6[0][0]                      \n",
            "                                                                 leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 1 32768       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 1 512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 2 0           add_7[0][0]                      \n",
            "                                                                 leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 1 32768       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 2 1024        conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 2 0           add_8[0][0]                      \n",
            "                                                                 leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 1 32768       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 2 1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 2 0           add_9[0][0]                      \n",
            "                                                                 leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 1 32768       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 2 1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 2 0           add_10[0][0]                     \n",
            "                                                                 leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 2 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 5 1179648     zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 5 2048        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 2 1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 5 2048        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 5 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 2 131072      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 2 1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 5 2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 5 0           add_12[0][0]                     \n",
            "                                                                 leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 2 131072      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 2 1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 5 2048        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 5 0           add_13[0][0]                     \n",
            "                                                                 leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 2 131072      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 2 1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 5 2048        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 5 0           add_14[0][0]                     \n",
            "                                                                 leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 2 131072      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 2 1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 5 2048        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 5 0           add_15[0][0]                     \n",
            "                                                                 leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 2 131072      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 2 1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 5 2048        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 5 0           add_16[0][0]                     \n",
            "                                                                 leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 2 131072      add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 2 1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 5 2048        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 5 0           add_17[0][0]                     \n",
            "                                                                 leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 2 131072      add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 2 1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 5 2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 5 0           add_18[0][0]                     \n",
            "                                                                 leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 5 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 4718592     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 4096        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 5 2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 4096        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 1 0           leaky_re_lu_44[0][0]             \n",
            "                                                                 leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 5 524288      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 5 2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 4096        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 1 0           add_20[0][0]                     \n",
            "                                                                 leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 5 524288      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 5 2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 4096        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 1 0           add_21[0][0]                     \n",
            "                                                                 leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 5 524288      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 5 2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 4096        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 1 0           add_22[0][0]                     \n",
            "                                                                 leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 5 524288      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 5 2048        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 4096        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 5 2048        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 4096        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 5 524288      leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 5 2048        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 2 1024        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 2 0           leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 2 196608      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 2 1024        conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 5 2048        conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 2 1024        conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 5 2048        conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 2 131072      leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 2 1024        conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 512         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 3 0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 49152       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 2 1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 512         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 2 1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 32768       leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 512         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 4718592     leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 5 1179648     leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 2 294912      leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 4096        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 5 2048        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 2 1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 5 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, None, None, 2 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 2 261375      leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 2 130815      leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 2 65535       leaky_re_lu_72[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Saved Keras model to model_data/yolo.h5\n",
            "Read 62001757 of 62001757.0 from Darknet weights.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwJE2GqsOQay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "outputId": "f1946f85-144e-4f9a-b00c-914dbfa0b9ad"
      },
      "source": [
        "pip install tensorflowjs==1.2.6"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs==1.2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/6a/b8da7692e9a289edbb83f4693ceb2c0be270ad30a5aee7438627e562ff95/tensorflowjs-1.2.6-py3-none-any.whl\n",
            "Collecting keras==2.2.4 (from tensorflowjs==1.2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 8.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub==0.5.0 (from tensorflowjs==1.2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/f18c352d84382d9c795a0f37eaf16d42ace7d161fbb0ad20bdcd5e550015/tensorflow_hub-0.5.0-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (2.8.0)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs==1.2.6) (1.14.0)\n",
            "Collecting numpy==1.16.4 (from tensorflowjs==1.2.6)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 44.8MB/s \n",
            "\u001b[?25hCollecting six==1.11.0 (from tensorflowjs==1.2.6)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs==1.2.6) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.5.0->tensorflowjs==1.2.6) (3.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs==1.2.6) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.5.0->tensorflowjs==1.2.6) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs==1.2.6) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs==1.2.6) (3.1.1)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, numpy, keras, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: numpy 1.16.5\n",
            "    Uninstalling numpy-1.16.5:\n",
            "      Successfully uninstalled numpy-1.16.5\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "  Found existing installation: tensorflow-hub 0.6.0\n",
            "    Uninstalling tensorflow-hub-0.6.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.6.0\n",
            "Successfully installed keras-2.2.4 numpy-1.16.4 six-1.11.0 tensorflow-hub-0.5.0 tensorflowjs-1.2.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVjGrAMaVf8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74c7484c-837b-447d-f80d-19882e892578"
      },
      "source": [
        "!tflite_convert \\\n",
        "  --output_file='/content/drive/My Drive/TensorFlow Lite/TfLite/yolov3.tflite' \\\n",
        "  --keras_model_file='/content/keras-yolo3/model_data/yolo.h5' \\"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-17 01:44:55.916493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-17 01:44:55.917129: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596e595ec40 executing computations on platform Host. Devices:\n",
            "2019-09-17 01:44:55.917203: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-17 01:44:55.923247: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-17 01:44:56.015109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.015993: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596e595f500 executing computations on platform CUDA. Devices:\n",
            "2019-09-17 01:44:56.016029: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-17 01:44:56.016227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.016914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-17 01:44:56.017369: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-17 01:44:56.019014: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-17 01:44:56.028883: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-17 01:44:56.029271: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-17 01:44:56.031020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-17 01:44:56.037735: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-17 01:44:56.042314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-17 01:44:56.042526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.043451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.044174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-17 01:44:56.047855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-17 01:44:56.049377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-17 01:44:56.049411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-17 01:44:56.049425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-17 01:44:56.055921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.056743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:44:56.057437: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-17 01:44:56.057491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0917 01:45:00.522216 140070969816960 hdf5_format.py:221] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "2019-09-17 01:45:00.662270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.663079: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2019-09-17 01:45:00.663353: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n",
            "2019-09-17 01:45:00.664135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.664788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-17 01:45:00.664871: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-17 01:45:00.664911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-17 01:45:00.664954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-17 01:45:00.664994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-17 01:45:00.665028: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-17 01:45:00.665052: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-17 01:45:00.665090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-17 01:45:00.665158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.665798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.666405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-17 01:45:00.666469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-17 01:45:00.666484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-17 01:45:00.666494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-17 01:45:00.666633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.667340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-17 01:45:00.667966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-09-17 01:45:00.890372: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\n",
            "2019-09-17 01:45:00.890444: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\n",
            "2019-09-17 01:45:00.890457: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "W0917 01:45:00.939316 140070969816960 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0917 01:45:00.939776 140070969816960 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "I0917 01:45:01.313332 140070969816960 graph_util_impl.py:311] Froze 366 variables.\n",
            "I0917 01:45:01.654875 140070969816960 graph_util_impl.py:364] Converted 366 variables to const ops.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tflite_convert\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 503, in main\n",
            "    app.run(main=run_main, argv=sys.argv[:1])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 499, in run_main\n",
            "    _convert_tf1_model(tflite_flags)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/tflite_convert.py\", line 193, in _convert_tf1_model\n",
            "    output_data = converter.convert()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/lite/python/lite.py\", line 811, in convert\n",
            "    _get_tensor_name(tensor), shape_list))\n",
            "ValueError: None is only supported in the 1st dimension. Tensor 'input_1' has invalid shape '[None, None, None, 3]'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNBvnsEyc2o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tflite_convert --output_file model.tflite \\\n",
        "                --saved_model_dir   ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03/saved_model/ \\\n",
        "                --output_format TFLITE \\\n",
        "                --inference_type FLOAT \\\n",
        "                --input_arrays image_tensor \\\n",
        "                --input_shapes 1,300,300,3 \\\n",
        "                --output_arrays detection_boxes,detection_classes,detection_scores,num_detections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHGE0JbTdapE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42d40b28-ae9e-4373-bf91-98f4278de65c"
      },
      "source": [
        "!tflite_convert -h"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: tflite_convert [-h] --output_file OUTPUT_FILE\n",
            "                      (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR | --keras_model_file KERAS_MODEL_FILE)\n",
            "                      [--output_format {TFLITE,GRAPHVIZ_DOT}]\n",
            "                      [--inference_type {FLOAT,QUANTIZED_UINT8}]\n",
            "                      [--inference_input_type {FLOAT,QUANTIZED_UINT8}]\n",
            "                      [--input_arrays INPUT_ARRAYS]\n",
            "                      [--input_shapes INPUT_SHAPES]\n",
            "                      [--output_arrays OUTPUT_ARRAYS]\n",
            "                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\n",
            "                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\n",
            "                      [--std_dev_values STD_DEV_VALUES]\n",
            "                      [--mean_values MEAN_VALUES]\n",
            "                      [--default_ranges_min DEFAULT_RANGES_MIN]\n",
            "                      [--default_ranges_max DEFAULT_RANGES_MAX]\n",
            "                      [--post_training_quantize] [--drop_control_dependency]\n",
            "                      [--reorder_across_fake_quant]\n",
            "                      [--change_concat_input_ranges {TRUE,FALSE}]\n",
            "                      [--allow_custom_ops] [--target_ops TARGET_OPS]\n",
            "                      [--dump_graphviz_dir DUMP_GRAPHVIZ_DIR]\n",
            "                      [--dump_graphviz_video]\n",
            "\n",
            "Command line tool to run TensorFlow Lite Converter.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --output_file OUTPUT_FILE\n",
            "                        Full filepath of the output file.\n",
            "  --graph_def_file GRAPH_DEF_FILE\n",
            "                        Full filepath of file containing frozen TensorFlow\n",
            "                        GraphDef.\n",
            "  --saved_model_dir SAVED_MODEL_DIR\n",
            "                        Full filepath of directory containing the SavedModel.\n",
            "  --keras_model_file KERAS_MODEL_FILE\n",
            "                        Full filepath of HDF5 file containing tf.Keras model.\n",
            "  --output_format {TFLITE,GRAPHVIZ_DOT}\n",
            "                        Output file format.\n",
            "  --inference_type {FLOAT,QUANTIZED_UINT8}\n",
            "                        Target data type of real-number arrays in the output\n",
            "                        file.\n",
            "  --inference_input_type {FLOAT,QUANTIZED_UINT8}\n",
            "                        Target data type of real-number input arrays. Allows\n",
            "                        for a different type for input arrays in the case of\n",
            "                        quantization.\n",
            "  --input_arrays INPUT_ARRAYS\n",
            "                        Names of the input arrays, comma-separated.\n",
            "  --input_shapes INPUT_SHAPES\n",
            "                        Shapes corresponding to --input_arrays, colon-\n",
            "                        separated.\n",
            "  --output_arrays OUTPUT_ARRAYS\n",
            "                        Names of the output arrays, comma-separated.\n",
            "  --saved_model_tag_set SAVED_MODEL_TAG_SET\n",
            "                        Comma-separated set of tags identifying the\n",
            "                        MetaGraphDef within the SavedModel to analyze. All\n",
            "                        tags must be present. In order to pass in an empty tag\n",
            "                        set, pass in \"\". (default \"serve\")\n",
            "  --saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY\n",
            "                        Key identifying the SignatureDef containing inputs and\n",
            "                        outputs. (default DEFAULT_SERVING_SIGNATURE_DEF_KEY)\n",
            "  --std_dev_values STD_DEV_VALUES\n",
            "                        Standard deviation of training data for each input\n",
            "                        tensor, comma-separated floats. Used for quantized\n",
            "                        input tensors. (default None)\n",
            "  --mean_values MEAN_VALUES\n",
            "                        Mean of training data for each input tensor, comma-\n",
            "                        separated floats. Used for quantized input tensors.\n",
            "                        (default None)\n",
            "  --default_ranges_min DEFAULT_RANGES_MIN\n",
            "                        Default value for min bound of min/max range values\n",
            "                        used for all arrays without a specified range,\n",
            "                        Intended for experimenting with quantization via\n",
            "                        \"dummy quantization\". (default None)\n",
            "  --default_ranges_max DEFAULT_RANGES_MAX\n",
            "                        Default value for max bound of min/max range values\n",
            "                        used for all arrays without a specified range,\n",
            "                        Intended for experimenting with quantization via\n",
            "                        \"dummy quantization\". (default None)\n",
            "  --post_training_quantize\n",
            "                        Boolean indicating whether to quantize the weights of\n",
            "                        the converted float model. Model size will be reduced\n",
            "                        and there will be latency improvements (at the cost of\n",
            "                        accuracy). (default False)\n",
            "  --drop_control_dependency\n",
            "                        Boolean indicating whether to drop control\n",
            "                        dependencies silently. This is due to TensorFlow not\n",
            "                        supporting control dependencies. (default True)\n",
            "  --reorder_across_fake_quant\n",
            "                        Boolean indicating whether to reorder FakeQuant nodes\n",
            "                        in unexpected locations. Used when the location of the\n",
            "                        FakeQuant nodes is preventing graph transformations\n",
            "                        necessary to convert the graph. Results in a graph\n",
            "                        that differs from the quantized training graph,\n",
            "                        potentially causing differing arithmetic behavior.\n",
            "                        (default False)\n",
            "  --change_concat_input_ranges {TRUE,FALSE}\n",
            "                        Boolean to change behavior of min/max ranges for\n",
            "                        inputs and outputs of the concat operator for\n",
            "                        quantized models. Changes the ranges of concat\n",
            "                        operator overlap when true. (default False)\n",
            "  --allow_custom_ops    Boolean indicating whether to allow custom operations.\n",
            "                        When false any unknown operation is an error. When\n",
            "                        true, custom ops are created for any op that is\n",
            "                        unknown. The developer will need to provide these to\n",
            "                        the TensorFlow Lite runtime with a custom resolver.\n",
            "                        (default False)\n",
            "  --target_ops TARGET_OPS\n",
            "                        Experimental flag, subject to change. Set of OpsSet\n",
            "                        options indicating which converter to use. Options:\n",
            "                        SELECT_TF_OPS,TFLITE_BUILTINS,TFLITE_BUILTINS_INT8.\n",
            "                        One or more option may be specified. (default\n",
            "                        set([OpsSet.TFLITE_BUILTINS]))\n",
            "  --dump_graphviz_dir DUMP_GRAPHVIZ_DIR\n",
            "                        Full filepath of folder to dump the graphs at various\n",
            "                        stages of processing GraphViz .dot files. Preferred\n",
            "                        over --output_format=GRAPHVIZ_DOT in order to keep the\n",
            "                        requirements of the output file.\n",
            "  --dump_graphviz_video\n",
            "                        Boolean indicating whether to dump the graph after\n",
            "                        every graph transformation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8oQs00ujHYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf49de7-1f87-4955-bea0-311b3e64d247"
      },
      "source": [
        "!input_tensor = model.layers[0].input"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: input_tensor: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffq8r30u4iUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUi2NIou6MKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "83e650fe-df1b-43fa-a263-ebfcc119d68f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TocoConverter.from_keras_model_file('/content/keras-yolo3/model_data/yolo.h5',\n",
        "                                                     input_shapes={'input_1': [1, 416, 416, 3]})\n",
        "converter.post_training_quantize = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"yolov3.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-88b27a4e2269>:4: TocoConverter.from_keras_model_file (from tensorflow.lite.python.lite) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `lite.TFLiteConverter.from_keras_model_file` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 366 variables.\n",
            "INFO:tensorflow:Converted 366 variables to const ops.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py:846: UserWarning: Property post_training_quantize is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "  \" instead.\" % name)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62049344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLD6LFsx6csX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1acbcf2-97da-4eb9-e806-876015dc2515"
      },
      "source": [
        "cd /content/keras-yolo3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-yolo3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xq6OrGv_Y5J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "df520b7f-3d44-41ad-d3c0-975fbb51cb14"
      },
      "source": [
        "# NOTE: Because of a bug in TensorFlow, this should be run in the console\n",
        "# NOTE: python tflite.py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.contrib.lite.python import lite\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "from darknet import darknet_base\n",
        "from definitions import ROOT_DIR\n",
        "\n",
        "inputs = Input(shape=(None, None, 3))\n",
        "# NOTE: Here, we do not include the YOLO head because TFLite does not\n",
        "# NOTE: support custom layers yet. Therefore, we'll need to implement\n",
        "# NOTE: the YOLO head ourselves.\n",
        "outputs, config = darknet_base(inputs, include_yolo_head=False)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model_path = '/content/keras-yolo3/model_data/yolo.h5'\n",
        "\n",
        "tf.keras.models.save_model(model, model_path, overwrite=True)\n",
        "\n",
        "# Sanity check to see if model loads properly\n",
        "# NOTE: See https://github.com/keras-team/keras/issues/4609#issuecomment-329292173\n",
        "# on why we have to pass in `tf: tf` in `custom_objects`\n",
        "model = tf.keras.models.load_model(model_path,\n",
        "                                   custom_objects={'tf': tf})\n",
        "\n",
        "converter = lite.TocoConverter.from_keras_model_file(model_path,\n",
        "                                                     input_shapes={'input_1': [1, config['width'], config['height'], 3]})\n",
        "converter.post_training_quantize = True\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(\"yolov3.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "\n",
            "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
            "\n",
            "  Please upgrade your code to TensorFlow 2.0:\n",
            "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
            "\n",
            "  Or install the latest stable TensorFlow 1.X release:\n",
            "    * `pip install -U \"tensorflow==1.*\"`\n",
            "\n",
            "  Otherwise your code may be broken by the change.\n",
            "\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-49ff5b82eb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib.lite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3weVfy_PAail",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c4af737c-212a-4f74-a1b3-3718530f7f8b"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.14.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorflow-estimator, numpy, tensorboard, wrapt, wheel, absl-py, termcolor, gast, six, google-pasta, protobuf, keras-preprocessing, astor, keras-applications, grpcio\n",
            "Required-by: tensorflowjs, stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dLIe-XdAk-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "52673a31-8132-4273-9551-d8b0f09371ad"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.6)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 1.2.0\n",
            "    Uninstalling tensorflow-1.2.0:\n",
            "      Successfully uninstalled tensorflow-1.2.0\n",
            "Successfully installed tensorflow-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcirsdR0ErrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "edc7a78d-8ae7-4a0b-fa26-f3dad6afa1cc"
      },
      "source": [
        "!tflite_convert \\\n",
        "  --output_file='/content/drive/My Drive/TensorFlow Lite/TfLite/yolov3.tflite' \\\n",
        "  --keras_model_file='/content/keras-yolo3/model_data/yolo.h5' \\\n",
        "  --output_format=TFLITE \\\n",
        "  --input_shape=1,416,416,3 \\\n",
        "  --input_array=input_1 "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-17 02:37:50.270962: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-09-17 02:37:50.275441: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-17 02:37:50.275675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14f12700 executing computations on platform Host. Devices:\n",
            "2019-09-17 02:37:50.275712: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-17 02:37:50.717069: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "W0917 02:37:52.301475 140152580937600 hdf5_format.py:221] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "2019-09-17 02:37:52.454114: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n",
            "2019-09-17 02:37:52.454321: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n",
            "2019-09-17 02:37:52.877703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize\n",
            "2019-09-17 02:37:52.877791: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
            "2019-09-17 02:37:52.877805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0917 02:37:52.941598 140152580937600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0917 02:37:52.941907 140152580937600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 366 variables.\n",
            "I0917 02:37:53.302613 140152580937600 graph_util_impl.py:311] Froze 366 variables.\n",
            "INFO:tensorflow:Converted 366 variables to const ops.\n",
            "I0917 02:37:53.676019 140152580937600 graph_util_impl.py:364] Converted 366 variables to const ops.\n",
            "2019-09-17 02:37:53.713455: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\n",
            "2019-09-17 02:37:53.713625: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\n",
            "2019-09-17 02:37:54.266607: E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node conv2d_1/kernel/Assign doesn't exist in graph\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}